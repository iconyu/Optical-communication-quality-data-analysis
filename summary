一、数据分析
训练集1855，测试集552，特征列13列，标签列为Q_real
 [wave,wss,evoa,oau,fiu,fib_652,fib_655,left,right,otu_power,OSNR,penalty,onsr]
1.训练集特征属性可视化
2.测试集特征属性可视化
我们可以通过可视化发现只有OSNR、onsr、out_power和penalty四列是有多种取值，wave列只有3种取值(9,29,49),其余列只有1种取值。出现这种情况是因为网络环境限制。
3.标签属性可视化
4.特征与标签之间相关性系数
选取测试集中特征和标签之间相关性系数排名前5的特征，详细查看它们之间的关系
 
二、建立基本模型
1.各模型的baseline
典型的回归问题，选择树形模型，所以没有对数据进行归一化或标准化。各种模型的baseline，使用了全部的特征，准确率计算公式：accuracy=  (sum(abs(pred_y-test_y )≤0.5))/(len(test_y))
选择模型	               测试集正确个数（共552条）
决策回归树                    310（随机变化）
GDBT	                     295（随机变化）
随机森林	                  312（随机变化）
AdaBoost                     305（随机变化）
Bagging	                     307（随机变化）
极端随机生成树ExtraTree        220（随机变化）
XGBoost	                     265
LightGBM	             300

2.XGBoost模型
由于在模型baseline中，XGBoost模型的准确率较高，所以对XGBoost进行优化。预测正确标准为“如果abs(pred_y – test_y) <= 0.5，预测正确”。选取全部特征，XGBoost模型所有参数设为默认值，552条数据正确265条。
1.先选择一个较高的学习率，加快收敛速度，找到最佳迭代次数n_estimators
	learning_rate = 0.1
	n_estimators可以先设成一个较大的数，不进行划分训练集和验证集，直接在cv结果中查看最优的迭代次数
  cv_params = {'n_estimators': [80,90,100,110]}
  其他参数初始化
  other_params = {'learning_rate': 0.1, 'n_estimators': 200, 'max_depth': 5}
  网格调参，最佳迭代次数n_estimators=90
  model = xgb.XGBRegressor(**other_params)
  optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='r2', cv=5, verbose=1, n_jobs=4)
  optimized_GBM.fit(X_train, y_train)
  减小n_estimators粒度，网格调参后最佳迭代次数n_estimators=90
  
2.调节参数max_depth
   通过网格调参后，经过多次试验，max_depth=15，
   cv_params = {'max_depth': [5, 8, 10, 15]}
   
3.调小学习率
   通过网格调参后，经过多次试验，learning_rate = 0.09
   cv_params = {‘learning_rate’: [0.01, 0.05, 0.09, 0.1]}
   
4.训练后最优模型，测试集522条中，预测正确296条
 
3.LightGBM模型
由于在模型baseline中，XGBoost模型的准确率较高，所以对XGBoost进行优化。预测正确标准为“如果abs(pred_y – test_y) <= 0.5，预测正确”。
1.选择较高的学习率，加快收敛的速度，这对于调参是很有必要的。
	learning_rate = 0.1
	确定估计器boosting_type的类型，默认选gbdt
	确定估计器的数目，也就是boosting迭代的次数/残差树的数目，n_estimators可以先设成一个较大的数，不进行划分训练集和验证集，直接在cv结果中查看最优的迭代次数。
  cv_results = lgb.cv(params, data, num_boost_round=1000, nfold=5, stratified=False, shuffle=True, metrics='rmse',early_stopping_rounds=50, verbose_eval=50, show_stdv=True, seed=0)
	给其他重要的参数一个初始值。
  params = {
    'boosting_type': 'gbdt', 
    'objective': 'regression', 
    'learning_rate': 0.1, 
    'num_leaves': 50, 
    'max_depth': 6,
    'subsample': 1, #数据采样率
    'colsample_bytree': 1, #特征采用率
          }

  初步结果为：best n_estimators:207
             
2.对决策树基本参数调参
	max_depth ：设置树深度，深度越大可能过拟合
	num_leaves：LightGBM使用的是leaf-wise的算法，在调节树的复杂程度时，使用的是num_leaves而不是max_depth。num_leaves 约小于2 max_depth
	同时调节这两个参数，对于这两个参数调优，我们先粗调，再细调。引入sklearn里的GridSearchCV()函数进行网格调参。
1）首先进行粗调
def lgbRegressor(data_train,label_train):
    model = lgb.LGBMRegressor(objective='regression',num_leaves=50,learning_rate=0.1, n_estimators=207, max_depth=6,metric='rmse', bagging_fraction = 1.0,feature_fraction = 1.0)
    params_test={
        'max_depth': [2,3,4,5,6,7,8,9,10],
        'num_leaves':[4,8,12,16,20,24,28]
                }
    model = GridSearchCV(estimator=model, param_grid=params_test, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=4)
    model.fit(data_train,label_train)
    print(model.best_params_)  #最好的参数集合
    return model
初步结果：
最好的模型参数：{max_depth:8，num_leaves:20}
模型分数：-0.101
 
2）然后在max_depth=8，num_leaves=20，附近进行细调
params_test={
    'max_depth': [7,8,9],
    'num_leaves':[17,18,19,20,21,22,23]
            }
初步结果：
最好的模型参数：{max_depth:7，num_leaves:19}
模型分数：-0.100
 
3.降低过拟合
	min_child_samples值取决于训练数据的样本个数和num_leaves. 将其设置的较大可以避免生成一个过深的树, 但有可能导致欠拟合。
1）首先进行粗调：
params_test={
    'min_child_samples': [5,10,15, 20, 25],
            }
初步结果：
最好的模型参数：{min_child_samples:5}
模型分数：-0.098            
 
    2）然后进行细调
params_test={
    'min_child_samples': [2,3,4,5,6,7,8],
           }        
 初步结果：
 最好的模型参数：{min_child_samples:5}
 模型分数：-0.098  
	feature_fraction参数来进行特征的子抽样。这个参数可以用来防止过拟合及提高训练速度。
  bagging_fraction+bagging_freq参数必须同时设置，bagging_fraction相当于subsample样本采样，可以使bagging更快的运行，同时也可以降拟合。
  bagging_freq默认0，表示bagging的频率，0意味着没有使用bagging，k意味着每k轮迭代进行一次bagging。
  params_test={
    'feature_fraction': [0.5, 0.6, 0.7, 0.8, 0.9,1.0],
    'bagging_fraction': [0.6, 0.7, 0.8, 0.9, 1.0]
              }
              
初步结果：
最好的模型参数：{bagging_fraction:0.6,feature_fraction:1.0}
模型分数：-0.098 
可以看到和上一步的模型分数一致，因此这两个参数可以不进行细调。

4. 降低学习率，最后提高准确率
	learning_rate=0.1，n_estimators=207，测试集准确的条数=270
	learning_rate=0.01, n_estimators=1577，测试集准确的条数=271
	learning_rate=0.001, n_estimators=2944, 测试集准确的条数=310

三、划分训练集
1.特征onsr，otu_power，OSNR与标签Q_real分布关系
2.训练集和测试集标签Q_real分布 
  由上图可以看到，训练集Q_real（红色线）的取值在蓝色竖线处出现明显的分层现象，通过定位发现index = 915，而测试集Q_real（蓝色线）的取值和训练集前半部分更符合。通过划分训练集，实验证明（基于XGBoost模型）：
	如果只用训练集前一半【0：915】进行训练，然后预测测试集，准确个数可以达到368条
	如果只用训练集后一半【915：1856】进行训练，然后预测测试集，准确个数为0
	如果用全部的训练集进行训练，然后预测测试集，准确个数为295
  因此，通过划分训练集，可以提高测试集预测的正确个数。
  
四、基于wave分组预测
1.基本步骤
1）通过观察发现Q_real与特征列wave、otu_power、OSNR有关。
2）wave的取值为1-80，对wave进行分组训练，可以得到80个模型。
3）通过查看测试集wave的取值，当wave_test = model_train_index时，用该model进行预测。
2.各模型的baseline
各个模型分别为：XGBoost/Lightgbm/DecisionTree/RandomForest/AdaBoost/GrandientBoost/Bagging/ExtraTree
                   表 各模型的预测正确数
Wave	训练集个数	测试集个数	XGB	LGBM	  DT	  RF	   Ada	  GBR	     Bag   Extra
9	   8	       184	 54	 0	  61	  59	    25	   42	     44	    25
29	   16          184	 0	 0	  0	  0	    0	    0	     0	    3
49	   25	       184	 161	 0	  0	  183	    0	    0	     167    4
总数	 49	      552      215     0	61	242	  25	  42	   211	  32

最优的模型为随机森林[59,0,183]，但是由于不稳定，综合考虑还是选择XGBoost模型[54,0,161]。

3.优化模型
1）放宽约束，不需要wave值严格相等。故先将训练集wave=[1,20]都划分为wave=9的训练集；wave=[21,40]都划分为wave=29的训练集；wave=[41,80]都划分为wave=9的训练集，可以看到预测的准确个数提高了。
                                  表 基于XGBoost模型的预测正确数
训练集划分	                            Wave=9	Wave=29	 Wave=49	总数
Wave[0-20]| Wave[21-40]| Wave[41-80]	19	     107	   184	     310

2）增加训练数据可以提高预测的正确率，进一步细化如何增加不同wave的训练集。我们可以将紧邻的wave值加入，扩大训练集。令wave_num为wave的数值
   +n：表示在原有训练集上，增加wave = wave_num+n的数据，扩展训练集
   -n：表示在原有训练集上，增加wave = wave_num+n的数据，扩展训练集
由下表可以看出，在原始训练集上增加wave_num+5的数据，可以提高预测准确率，此时预测正确总数最大。
对于不同的通道，进行不同的训练集划分，可以达到各自预测的峰值，进一步提高预测正确总数，但是测试之前不知道这种划分。
表 不同训练集划分的预测结果（不完全列出）
训练集划分	Wave=9	Wave=29	Wave=49	预测正确总数
+1	147	0	25	172
+2	14	0	171	185
+3	112	0	182	294
+4	24	0	182	206
+5	170	133	184	487
+6	62	6	0	68
-1	40	115	16	171
-2	40	127	59	226
-3	51	22	14	87
-1-3	9	144	7	160
+1+3	179	0	18	197
    在预测正确总数最高的基础上，通过网格调参，发现XGBoost模型的参数设置为max_depth=3,n_estimators=86,learning_rates=0.1时，预测总数有细微提升，但总体来说不大。
训练集划分	   Wave=9   Wave=29 Wave=49 预测正确总数
wave+(wave+ 5)	171	136	184	491

五、回归预测改分类预测
1.设置分类标签
Q_real的取值为[ 0 , 16)，由于回归误差计算是以0.5为标准，因此分类间隔设置为0.5，可以分为32类。如[0,0.5) 、[0.5,1)， [1,1.5)…… [15.5,16)
#设置分类标签
def makeLabel(label,step=0.5):
    tag = []
    for i in label:
         a = i // step
         tag.append(a)
    return tag
    
2.计算各种模型的baseline
模型	测试集正确个数
决策树	  120（随机变化）
随机森林	 107（随机变化）
AdaBoost    44
GDBT	    117（随机变化）
XGBoost	    121
LightGBM    79
    可以看到，分类的结果比回归的结果要差很多，可能是因为丢失掉Q_real数值的小数点部分的信息，Q_real的细微差别是体现在数值的小数部分，而分类直接将该部分的信息丢失，导致结果变差。

3.改变分类区间
    通过分析发现Q_real在0-7之间没有值，目前训练集和测试集中Q_real的取值范围在7-16之间，所以标签值分类区间缩小，重新设置为[7,16)。结果没有多大变化，因为之前标签的取值也没有取到0-14之间，所以标签的区间范围没有关系。就以[0,16]作为范围。

4.使用新的分类预测模型
由于基本模型如决策树、随机森林、XGBoost、Lightgbm等算法都无法很好的分类预测出Q_real的值，因此通过阅读论文查看能否找到新的模型从而提高预测的准确度。目前较多的方法是将树的思想和神经网络的思想结合起来，例如提出了深度树gcForest模型和神经网络随机森林neural random forests模型。
1）深度树gcForest（multi-Grained Cascade Forest）
1. 深度树的优点
周志华教授在2017年提出了一种决策树集成方法：深度树gcForest。
1）与需要在超参数调整方面付出巨大努力的深度神经网络相比，gcForest更容易训练。
2）应用于不同域的不同数据，也可以通过几乎相同的超参数设置来实现优异的性能。 
3）可以根据可用的计算资源控制培训成本，提高效率。
4）也适用于小规模的训练数据。
论文中比较了各种算法在各个数据集如MNIST数据集、面部识别、情感分析、低维度数据集等上面的准确率，发现深度树的表现由于随机森林和神经网络。
2.深度树的结构
由完全随机森林和随机森林两种森林组成，包含多粒度扫描multi-grained scanning和级联层cascade，基本结构如下图。
3.应用到本数据集想法
设置gcForest结构，输入13个特征值，窗口大小为3。初始化gcForest如下，后续需要调整结构，使其更适合该数据集。
 
2）神经网络随机森林neural random forests模型
1.神经网络随机森林结构
给定随机化回归树的集合，可以将它们重构为具有特定连接权重的多层神经网络的集合，这些神经网络具有稀疏连接和对决策边界几何的较少限制。它们的激活函数是软非线性和可微分的，可通过基于梯度的优化算法进行训练，并且期望表现出更好的泛化性能。
2. 神经网络随机森林优点
神经网络的许多参数使它们成为用于复杂数据建模的通用且富有表现力的工具,但他们的表现力带来了增加过度拟合风险的缺点，特别是在小型数据集上。而随机森林调整的参数较少，但是正交超平面的贪婪特征空间分离导致典型的阶梯或类似于决策的表面，这对于某些数据可能是有利的，但对于其他数据可能是次优的，特别是对于具有相关特征的共线数据。将随机森林投射到神经网络框架中的优势，可以利用两种方法的优势来克服各自的缺点。并且论文中实验已经证明在模拟和实际数据集上，在大多数情况下都优于随机森林和神经网络。
3.应用到本数据集想法
构建本数据集的神经网络随机森林网络。输入层选择13个特征中与Q_real强相关的5个特征wave、out_power、OSNR、onsr、penalty。输出层中是分类区间为[7,16,step=0.5]，共18个种类中的某几类。隐藏层由随机化回归树决定。最后将每棵树输出的结果总和，找到数值最大的结果，作为预测输出。

