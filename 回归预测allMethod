import pandas as pd
from sklearn.tree import DecisionTreeRegressor,ExtraTreeRegressor
from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor,BaggingRegressor
import xgboost as xgb
import lightgbm as lgb

def readTrainFile(url):
    df = pd.read_csv(url)
    data = df.iloc[:,1:-4]
    label = df.iloc[:,-3]
    '''
    wave = df.wave
    wss = df.wss
    evoa = df.evoa
    oau = df.oau
    fiu = df.fiu
    fib_652 = df.fib_652
    fib_655 = df.fib_655
    left = df.left  
    right = df.right
    otu_power = df.otu_power
    OSNR = df.OSNR
    penalty = df.penalty
    onsr = df.onsr
    #data = pd.concat([wave,otu_power,OSNR,penalty,onsr],axis=1)
    '''
    return df,data,label

def readTestFile(url):
    df = pd.read_csv(url)
    data = df.iloc[:,1:-1]
    label = df.iloc[:,-1]
    '''
    wave = df.wave
    wss = df.wss
    evoa = df.evoa
    oau = df.oau
    fiu = df.fiu
    fib_652 = df.fib_652
    fib_655 = df.fib_655
    left = df.left  
    right = df.right
    otu_power = df.otu_power
    OSNR = df.OSNR
    penalty = df.penalty
    onsr = df.onsr
    #data = pd.concat([wave,otu_power,OSNR,penalty,onsr],axis=1)
    '''
    return df,data,label

#决策树回归
def decisionTreeRegressor(X_train,y_train):
    model = DecisionTreeRegressor()
    model.fit(X_train,y_train)
    return model
#随机森林回归
def randomForestRegressor(X_train,y_train):
    model = RandomForestRegressor()
    model.fit(X_train,y_train)
    return model
#Adaboost回归
def Adaboost(X_train,y_train):
    model = AdaBoostRegressor()
    model.fit(X_train,y_train)
    return model
#GBRT回归
def GBRT(X_train,y_train):
    model = GradientBoostingRegressor()
    model.fit(X_train,y_train)
    return model
#Bagging回归
def Bag(X_train,y_train):
    model = BaggingRegressor()
    model.fit(X_train,y_train)
    return model
#极端随机树回归
def extra(X_train,y_train):
    model = ExtraTreeRegressor()
    model.fit(X_train,y_train)
    return model
#xgb回归
def xgbRegressor(X_train,y_train):
    model = xgb.XGBRegressor()
    model.fit(X_train,y_train)
    return model
#lgbm回归
def lgbRegressor(X_train,y_train):
    model = lgb.LGBMRegressor()
    model.fit(X_train,y_train)
    return model
    
#计算测试集准确率    
def test(X_test,y_test,model):
    pred_y = model.predict(X_test)
    y_test = y_test.values
    acc = sum(abs(pred_y - y_test) <= 0.5) / float(len(y_test))
    print('测试集满足条件的个数',sum(abs(pred_y - y_test) <= 0.5))
    print(acc)


if __name__ == '__main__':
    df_train,data_train,label_train = readTrainFile('train_with_expm.csv')
    df_test,data_test,label_test = readTestFile('fand.csv')

    #model = decisionTreeRegressor(data_train,label_train)
    #model = randomForestRegressor(data_train,label_train)
    #model = Adaboost(data_train,label_train)
    #model = GBRT(data_train,label_train)
    #model = Bag(data_train,label_train)
    #model = extra(data_train,label_train)
    #model = xgbRegressor(data_train,label_train)
    model = lgbRegressor(data_train,label_train)
    test(data_test,label_test,model)

    
